{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Consumer Reviews Summarization - Project Part 3\n","\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Ariamestra/ConsumerReviews/blob/main/project_part3.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ariamestra/ConsumerReviews/blob/main/project_part3.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction\n","My goal for this project is to develop a system capable of generating concise summaries of customer reviews. This will help users in quickly skim through feedback on products by transforming detailed reviews into short comments. These comments will be categorized as positive, neutral, or negative, corresponding to the sentiment of the rating provided. To achieve this, the system will use the capabilities of the pre-trained T5 model. I selected the T5 model as my pre-trained choice because it is a text-to-text transformer, thats good at tasks like summarization. I opted for T5-small due to its size, which is more manageable. Additionally, T5 is versatile in handling different summarization types, like extractive summarization where it picks out important sentences from the text.<br>\n","<br>\n","\n","**Data** <br>\n","The dataset was sourced from Kaggle, specifically the [Consumer Review of Clothing Product](https://www.kaggle.com/datasets/jocelyndumlao/consumer-review-of-clothing-product)\n"," dataset. This dataset includes customer reviews from Amazon. It has all sorts of feedback from buyers about different products. Along with the customers' actual reviews, ratings, product type, material, construction, color, finish, and durability.<br>\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Shape: (49338, 9)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Review</th>\n","      <th>Cons_rating</th>\n","      <th>Cloth_class</th>\n","      <th>Materials</th>\n","      <th>Construction</th>\n","      <th>Color</th>\n","      <th>Finishing</th>\n","      <th>Durability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>Intimates</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>Pants</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>Blouses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Title                                             Review  \\\n","0                      NaN  Absolutely wonderful - silky and sexy and comf...   \n","1                      NaN  Love this dress!  it's sooo pretty.  i happene...   \n","2  Some major design flaws  I had such high hopes for this dress and reall...   \n","3         My favorite buy!  I love, love, love this jumpsuit. it's fun, fl...   \n","4         Flattering shirt  This shirt is very flattering to all due to th...   \n","\n","   Cons_rating Cloth_class  Materials  Construction  Color  Finishing  \\\n","0          4.0   Intimates        0.0           0.0    0.0        1.0   \n","1          5.0     Dresses        0.0           1.0    0.0        0.0   \n","2          3.0     Dresses        0.0           0.0    0.0        1.0   \n","3          5.0       Pants        0.0           0.0    0.0        0.0   \n","4          5.0     Blouses        0.0           1.0    0.0        0.0   \n","\n","   Durability  \n","0         0.0  \n","1         0.0  \n","2         0.0  \n","3         0.0  \n","4         0.0  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Import all packages needed\n","#!pip install transformers pandas nltk scikit-learn\n","#!pip install sentencepiece\n","#!pip install transformers[torch]\n","\n","\n","import pandas as pd\n","import re\n","import nltk\n","import torch\n","import sys\n","import sentencepiece as spm\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('punkt')       \n","nltk.download('stopwords')  \n","nltk.download('wordnet')     \n","\n","MODEL_NAME = 't5-small'\n","model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n","tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n","\n","data_URL = 'https://raw.githubusercontent.com/Ariamestra/ConsumerReviews/main/Reviews.csv'\n","df = pd.read_csv(data_URL)\n","print(f\"Shape: {df.shape}\")\n","df.head()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["'\\n# Drop all rows with any null values\\ndf = df.dropna()\\nprint(f\"Shape: {df.shape}\")\\ndf.head()\\n\\n# Make lowercase\\ndf[\\'Review\\'] = df[\\'Review\\'].str.lower()\\n\\n# Remove punctuation\\ndf[\\'Review\\'] = df[\\'Review\\'].apply(lambda x: re.sub(r\\'[^\\\\w\\\\s]\\', \\'\\', x))\\n\\n# Tokenize reviews\\ndf[\\'Review\\'] = df[\\'Review\\'].apply(word_tokenize)\\n\\n# Remove stop words\\nstop_words = set(stopwords.words(\\'english\\'))\\ndf[\\'Review\\'] = df[\\'Review\\'].apply(lambda x: [word for word in x if word not in stop_words])\\n\\n# Lemmatize the words\\nlemmatizer = WordNetLemmatizer()\\ndf[\\'Review\\'] = df[\\'Review\\'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\\n\\n# Join the words\\ndf[\\'Review\\'] = df[\\'Review\\'].apply(lambda x: \\' \\'.join(x))\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","# Drop all rows with any null values\n","df = df.dropna()\n","print(f\"Shape: {df.shape}\")\n","df.head()\n","\n","# Make lowercase\n","df['Review'] = df['Review'].str.lower()\n","\n","# Remove punctuation\n","df['Review'] = df['Review'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","# Tokenize reviews\n","df['Review'] = df['Review'].apply(word_tokenize)\n","\n","# Remove stop words\n","stop_words = set(stopwords.words('english'))\n","df['Review'] = df['Review'].apply(lambda x: [word for word in x if word not in stop_words])\n","\n","# Lemmatize the words\n","lemmatizer = WordNetLemmatizer()\n","df['Review'] = df['Review'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","# Join the words\n","df['Review'] = df['Review'].apply(lambda x: ' '.join(x))\n","'''"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["'\\n# Split the dataset\\nX_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\\n\\n# Reset the indices \\nX_train = X_train.reset_index(drop=True)\\nX_test = X_test.reset_index(drop=True)\\n\\ntotal_samples = df.shape[0]\\ntrain_size = X_train.shape[0]\\ntest_size = X_test.shape[0]\\n\\ntrain_percentage = (train_size / total_samples) * 100\\ntest_percentage = (test_size / total_samples) * 100\\n\\nprint(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\\nprint(f\"Test size: {test_size} ({test_percentage:.2f}%)\")\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","# Split the dataset\n","X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Reset the indices \n","X_train = X_train.reset_index(drop=True)\n","X_test = X_test.reset_index(drop=True)\n","\n","total_samples = df.shape[0]\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","\n","train_percentage = (train_size / total_samples) * 100\n","test_percentage = (test_size / total_samples) * 100\n","\n","print(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\n","print(f\"Test size: {test_size} ({test_percentage:.2f}%)\")\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure."]},{"cell_type":"markdown","metadata":{},"source":["Model training"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nulls in the reviews: 831\n","Number of nulls in the ratings: 214\n","Number of rows dropped: 1043\n","Shape of the DataFrame after dropping rows: (48295, 9)\n"]}],"source":["# Count the number of nulls in reviews\n","number_of_nulls = df['Review'].isnull().sum()\n","print(f\"Number of nulls in the reviews: {number_of_nulls}\")\n","\n","# Calculate the number of nulls in rating\n","number_of_nulls_in_ratings = df['Cons_rating'].isnull().sum()\n","print(f\"Number of nulls in the ratings: {number_of_nulls_in_ratings}\")\n","\n","original_count = df.shape[0]\n","df_cleaned = df.dropna(subset=['Review', 'Cons_rating']) # Drop rows with nulls in reviews and ratings columns\n","cleaned_count = df_cleaned.shape[0] # Number of rows after dropping nulls\n","rows_dropped = original_count - cleaned_count\n","\n","print(f\"Number of rows dropped: {rows_dropped}\")\n","\n","# Get the shape after dropping null values\n","df_shape_after_dropping = df_cleaned.shape\n","\n","print(f\"Shape of the DataFrame after dropping rows: {df_shape_after_dropping}\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Longest review length: 668 words\n","Shortest review length: 20 words\n","Shape of the DataFrame after dropping rows below 20 words: (32857, 10)\n"]}],"source":["# Review length of reviews\n","df_cleaned = df_cleaned.copy()\n","df_cleaned['Review_length'] = df_cleaned['Review'].apply(lambda x: len(str(x).split()))\n","\n","# Filter out reviews that are shorter than 20 words \n","df_cleaned.drop(df_cleaned[df_cleaned['Review_length'] < 20].index, inplace=True)\n","\n","# Longest and shortest reviews in df_cleaned\n","longest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmax()]\n","longest_review = longest_review_row['Review']\n","longest_review_length = longest_review_row['Review_length']\n","\n","shortest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmin()]\n","shortest_review = shortest_review_row['Review']\n","shortest_review_length = shortest_review_row['Review_length']\n","\n","print(f\"Longest review length: {longest_review_length} words\")\n","print(f\"Shortest review length: {shortest_review_length} words\")\n","print(f\"Shape of the DataFrame after dropping rows below 20 words: {df_cleaned.shape}\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n"]}],"source":["# Clean reviews\n","stop_words = set(stopwords.words('english'))\n","\n","def clean_review(review):\n","    review = str(review).lower()\n","    review = review.translate(str.maketrans('', '', string.punctuation))\n","    # Tokenize and remove stop words\n","    words = word_tokenize(review)\n","    words = [word for word in words if word.isalpha() and word not in stop_words]\n","    # Join string\n","    review = ' '.join(words)\n","    return review\n","\n","print(f\"Done\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total dataset size: 32857\n","Train size: 26285 (80.00%)\n","Test size: 6572 (20.00%)\n"]}],"source":["# Converts it to a numerical format using TF-IDF vectorization and then splits the dataset into training and test sets.\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","import string\n","\n","df_cleaned['Processed_Review'] = df_cleaned['Review'].apply(clean_review)\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(df_cleaned['Processed_Review'], df_cleaned['Cons_rating'], test_size=0.2, random_state=42)\n","\n","# Initialize the TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', max_df=0.95, min_df=0.05)\n","\n","# Fit to the training data \n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","X = df_cleaned['Processed_Review']\n","y = df_cleaned['Cons_rating']\n","\n","# Now you can proceed with your existing train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","\n","# Calculate the total number \n","total_samples = X.shape[0]\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","\n","\n","train_percentage = (train_size / total_samples) * 100\n","test_percentage = (test_size / total_samples) * 100\n","\n","print(f\"Total dataset size: {total_samples}\")\n","print(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\n","print(f\"Test size: {test_size} ({test_percentage:.2f}%)\")"]},{"cell_type":"markdown","metadata":{},"source":["Model Fine Tuning"]},{"cell_type":"markdown","metadata":{},"source":["Model Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Summerization"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","In conclusion, the project has successfully used the pre-trained T5 model to transform extensive customer reviews into brief summaries. This advancement not only enhances the efficiency of user evaluations by providing understanding into product feedback. The implementation of this summarization tool shows practical use of text-to-text transformers in real-world scenarios, simplifying the decision-making process for consumers."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
