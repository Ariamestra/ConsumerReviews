{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Consumer Reviews Summarization - Project Part 3\n","\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Ariamestra/ConsumerReviews/blob/main/project_part3.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ariamestra/ConsumerReviews/blob/main/project_part3.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction\n","My goal for this project is to develop a system capable of generating concise summaries of customer reviews. This will help users in quickly skim through feedback on products by transforming detailed reviews into short comments. These comments will be categorized as positive, neutral, or negative, corresponding to the sentiment of the rating provided. To achieve this, the system will use the capabilities of the pre-trained T5 model. I selected the T5 model as my pre-trained choice because it is a text-to-text transformer, thats good at tasks like summarization. I opted for T5-small due to its size, which is more manageable. Additionally, T5 is versatile in handling different summarization types, like extractive summarization where it picks out important sentences from the text.<br>\n","<br>\n","\n","**Data** <br>\n","The dataset was sourced from Kaggle, specifically the [Consumer Review of Clothing Product](https://www.kaggle.com/datasets/jocelyndumlao/consumer-review-of-clothing-product)\n"," dataset. This dataset includes customer reviews from Amazon. It has all sorts of feedback from buyers about different products. Along with the customers' actual reviews, ratings, product type, material, construction, color, finish, and durability.<br>\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /home/codespace/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Shape: (49338, 9)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Review</th>\n","      <th>Cons_rating</th>\n","      <th>Cloth_class</th>\n","      <th>Materials</th>\n","      <th>Construction</th>\n","      <th>Color</th>\n","      <th>Finishing</th>\n","      <th>Durability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>Intimates</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>Pants</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>Blouses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Title                                             Review  \\\n","0                      NaN  Absolutely wonderful - silky and sexy and comf...   \n","1                      NaN  Love this dress!  it's sooo pretty.  i happene...   \n","2  Some major design flaws  I had such high hopes for this dress and reall...   \n","3         My favorite buy!  I love, love, love this jumpsuit. it's fun, fl...   \n","4         Flattering shirt  This shirt is very flattering to all due to th...   \n","\n","   Cons_rating Cloth_class  Materials  Construction  Color  Finishing  \\\n","0          4.0   Intimates        0.0           0.0    0.0        1.0   \n","1          5.0     Dresses        0.0           1.0    0.0        0.0   \n","2          3.0     Dresses        0.0           0.0    0.0        1.0   \n","3          5.0       Pants        0.0           0.0    0.0        0.0   \n","4          5.0     Blouses        0.0           1.0    0.0        0.0   \n","\n","   Durability  \n","0         0.0  \n","1         0.0  \n","2         0.0  \n","3         0.0  \n","4         0.0  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# Import all packages needed\n","#!pip install transformers pandas nltk scikit-learn\n","#!pip install sentencepiece\n","#!pip install transformers[torch]\n","\n","\n","import pandas as pd\n","import re\n","import nltk\n","import torch\n","import sys\n","import sentencepiece as spm\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('punkt')       \n","nltk.download('stopwords')  \n","nltk.download('wordnet')     \n","\n","MODEL_NAME = 't5-small'\n","model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n","tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n","\n","data_URL = 'https://raw.githubusercontent.com/Ariamestra/ConsumerReviews/main/Reviews.csv'\n","df = pd.read_csv(data_URL)\n","print(f\"Shape: {df.shape}\")\n","df.head()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape: (5442, 9)\n"]}],"source":["# Drop all rows with any null values\n","df = df.dropna()\n","print(f\"Shape: {df.shape}\")\n","df.head()\n","\n","# Make lowercase\n","df['Review'] = df['Review'].str.lower()\n","\n","# Remove punctuation\n","df['Review'] = df['Review'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","# Tokenize reviews\n","df['Review'] = df['Review'].apply(word_tokenize)\n","\n","# Remove stop words\n","stop_words = set(stopwords.words('english'))\n","df['Review'] = df['Review'].apply(lambda x: [word for word in x if word not in stop_words])\n","\n","# Lemmatize the words\n","lemmatizer = WordNetLemmatizer()\n","df['Review'] = df['Review'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","# Join the words\n","df['Review'] = df['Review'].apply(lambda x: ' '.join(x))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 4353 (79.99%)\n","Test size: 1089 (20.01%)\n"]}],"source":["# Split the dataset\n","X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","total_samples = df.shape[0]\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","\n","train_percentage = (train_size / total_samples) * 100\n","test_percentage = (test_size / total_samples) * 100\n","\n","print(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\n","print(f\"Test size: {test_size} ({test_percentage:.2f}%)\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 4353 (79.99%)\n","Test size: 1089 (20.01%)\n"]}],"source":["# Split the dataset\n","X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Reset the indices \n","X_train = X_train.reset_index(drop=True)\n","X_test = X_test.reset_index(drop=True)\n","\n","total_samples = df.shape[0]\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","\n","train_percentage = (train_size / total_samples) * 100\n","test_percentage = (test_size / total_samples) * 100\n","\n","print(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\n","print(f\"Test size: {test_size} ({test_percentage:.2f}%)\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","# -------------------------------------------------------------------------------------------------------------------\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.max_length = max_length\n","        self.text = dataframe['Review'].tolist()  # 'text' should be the column with text data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        return {\n","            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n","            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n","            'labels': torch.tensor(self.data['Cons_rating'][index], dtype=torch.long)  # 'label' should be the column with label data\n","        }\n","\n","# Assuming you have a tokenizer available\n","train_dataset = CustomDataset(X_train, tokenizer, max_length=512)\n","eval_dataset = CustomDataset(X_test, tokenizer, max_length=512)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomDataset(Dataset):\n","    # ... other methods ...\n","\n","    def __getitem__(self, index):\n","        # Assuming self.texts and self.labels are initialized and populated\n","        # with the dataset's features and labels respectively\n","        \n","        # Tokenize the text to get input_ids and attention_mask\n","        inputs = self.tokenizer.encode_plus(\n","            self.texts[index],\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt' # Ensure that the tokenizer returns PyTorch tensors\n","        )\n","        \n","        # Retrieve the label\n","        label = torch.tensor(self.labels[index], dtype=torch.long)\n","        \n","        # Return a dictionary in the format expected by the Trainer class\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(), # Remove the batch dimension\n","            'attention_mask': inputs['attention_mask'].squeeze(), # Remove the batch dimension\n","            'labels': label\n","        }\n","\n","# Assuming tokenizer, self.texts, self.labels, and self.max_length are defined\n","# You would initialize your dataset like this:\n","dataset = CustomDataset(tokenizer=tokenizer, texts=texts, labels=labels, max_length=512)\n","\n","# Then create the DataLoader\n","data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","# When you iterate over the DataLoader, it will collate the individual items\n","# into a single batch, which is then formatted correctly for the Trainer\n","for batch in data_loader:\n","    # Now batch is a dictionary with the keys 'input_ids', 'attention_mask', and 'labels'\n","    # where the values are tensors with the first dimension being the batch size\n","    print(batch['input_ids'].shape)  # e.g., torch.Size([32, 512])\n","    print(batch['attention_mask'].shape)  # e.g., torch.Size([32, 512])\n","    print(batch['labels'].shape)  # e.g., torch.Size([32])\n","    break  # Just as an example to print the first batch\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 512])\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","# Define the batch size you want\n","batch_size = 32\n","\n","# Create the DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","first_batch = next(iter(train_loader))\n","print(first_batch['input_ids'].shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def __getitem__(self, index):\n","    # Retrieve the input data\n","    inputs = self.tokenizer.encode_plus(\n","        self.texts[index],\n","        max_length=self.max_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","\n","    # Extract the input IDs and attention mask\n","    input_ids = inputs['input_ids'].squeeze()\n","    attention_mask = inputs['attention_mask'].squeeze()\n","\n","    # Retrieve the label\n","    label = torch.tensor(self.labels[index], dtype=torch.long)\n","\n","    # Return a dictionary\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attention_mask,\n","        'labels': label\n","    }\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"not enough values to unpack (expected 2, got 1)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/workspaces/ConsumerReviews/project_part3.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./results\u001b[39m\u001b[39m'\u001b[39m,          \u001b[39m# output directory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,              \u001b[39m# total number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,     \u001b[39m# evaluate each `logging_steps`\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,                         \u001b[39m# the instantiated Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                  \u001b[39m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,         \u001b[39m# training dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39meval_dataset,          \u001b[39m# evaluation dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bmusical-giggle-66r6p7v7rw5c4wxq/workspaces/ConsumerReviews/project_part3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2749\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1746\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1745\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1746\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1747\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1748\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1749\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1750\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1751\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1752\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1753\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1754\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1755\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1756\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1757\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1758\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1759\u001b[0m )\n\u001b[1;32m   1761\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1763\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1018\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1016\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m-> 1018\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m   1020\u001b[0m \u001b[39m# required mask seq length can be calculated via length of past\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m mask_seq_length \u001b[39m=\u001b[39m past_key_values[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m seq_length \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m seq_length\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"]}],"source":["from transformers import Trainer, TrainingArguments\n","import torch\n","\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    num_train_epochs=3,              \n","    per_device_train_batch_size=8,  \n","    per_device_eval_batch_size=16,   \n","    warmup_steps=500,                \n","    weight_decay=0.01,               \n","    logging_dir='./logs',            \n","    logging_steps=10,\n","    do_train=True,\n","    do_eval=True,\n","    evaluation_strategy=\"epoch\",     \n",")\n","\n","trainer = Trainer(\n","    model=model,                        \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=eval_dataset,          \n",")\n","\n","trainer.train()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate and save model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.evaluate()\n","\n","model.save_pretrained('./my_model')\n","tokenizer.save_pretrained('./my_model')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def summarize_review(review):\n","    input_ids = tokenizer.encode(\"summarize: \" + review, return_tensors=\"pt\")\n","    summary_ids = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","for review in reviews[:5]:\n","    summarized_review = summarize_review(review)\n","    print(f\"Original review: {review}\")\n","    print(f\"Summarized review: {summarized_review}\\n\")\n","    print(\"\")"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","In conclusion, the project has successfully used the pre-trained T5 model to transform extensive customer reviews into brief summaries. This advancement not only enhances the efficiency of user evaluations by providing understanding into product feedback. The implementation of this summarization tool shows practical use of text-to-text transformers in real-world scenarios, simplifying the decision-making process for consumers."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
