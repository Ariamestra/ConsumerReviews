{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Consumer Reviews Summarization - Project Part 2\n","\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Ariamestra/ConsumerReviews/blob/main/project_part2.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ariamestra/ConsumerReviews/blob/main/project_part2.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction\n","My project goal is to develop a baseline model using a Naive Bayes classifier, designed to summarize customer reviews. This is intended to help potential buyers quickly navigate through reviews when assessing a product. The system will focus on condensing the essential content of each review and its associated rating into a concise, single-sentence comment. These comments will be categorized as positive, neutral, or negative, aligning with the review's original rating. This approach will simplify the review evaluation process, making it more efficient.<br>\n","<br>\n","**Data** <br>\n","The dataset was sourced from Kaggle, specifically the [Consumer Review of Clothing Product](https://www.kaggle.com/datasets/jocelyndumlao/consumer-review-of-clothing-product)\n"," dataset. This dataset includes customer reviews from Amazon. It has all sorts of feedback from buyers about different products. Along with the customers' actual reviews, ratings, product type, material, construction, color, finish, and durability.<br>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Prep"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape: (49338, 9)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Review</th>\n","      <th>Cons_rating</th>\n","      <th>Cloth_class</th>\n","      <th>Materials</th>\n","      <th>Construction</th>\n","      <th>Color</th>\n","      <th>Finishing</th>\n","      <th>Durability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>Intimates</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>Pants</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>Blouses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Title                                             Review  \\\n","0                      NaN  Absolutely wonderful - silky and sexy and comf...   \n","1                      NaN  Love this dress!  it's sooo pretty.  i happene...   \n","2  Some major design flaws  I had such high hopes for this dress and reall...   \n","3         My favorite buy!  I love, love, love this jumpsuit. it's fun, fl...   \n","4         Flattering shirt  This shirt is very flattering to all due to th...   \n","\n","   Cons_rating Cloth_class  Materials  Construction  Color  Finishing  \\\n","0          4.0   Intimates        0.0           0.0    0.0        1.0   \n","1          5.0     Dresses        0.0           1.0    0.0        0.0   \n","2          3.0     Dresses        0.0           0.0    0.0        1.0   \n","3          5.0       Pants        0.0           0.0    0.0        0.0   \n","4          5.0     Blouses        0.0           1.0    0.0        0.0   \n","\n","   Durability  \n","0         0.0  \n","1         0.0  \n","2         0.0  \n","3         0.0  \n","4         0.0  "]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# Import all of the Python Modules/Packages \n","#!pip install -U imbalanced-learn\n","\n","import pandas as pd\n","from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import string\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","from nltk.probability import FreqDist\n","from heapq import nlargest\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import SMOTE # Data transformer because when split traning data it 99% positive\n","\n","\n","\n","from nltk.probability import FreqDist\n","\n","\n","# Now download NLTK resources\n","#nltk.download('stopwords')\n","#nltk.download('punkt')\n","\n","data_URL = 'https://raw.githubusercontent.com/Ariamestra/ConsumerReviews/main/Reviews.csv'\n","df = pd.read_csv(data_URL)\n","print(f\"Shape: {df.shape}\")\n","df.head()"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nulls in the reviews: 831\n","Number of nulls in the ratings: 214\n","Number of rows dropped: 1043\n","Shape of the DataFrame after dropping rows: (48295, 10)\n"]}],"source":["# Count the number of nulls in reviews\n","number_of_nulls = df['Review'].isnull().sum()\n","print(f\"Number of nulls in the reviews: {number_of_nulls}\")\n","\n","# Calculate the number of nulls in rating\n","number_of_nulls_in_ratings = df['Cons_rating'].isnull().sum()\n","print(f\"Number of nulls in the ratings: {number_of_nulls_in_ratings}\")\n","\n","original_count = df.shape[0]\n","df_cleaned = df.dropna(subset=['Review', 'Cons_rating']) # Drop rows with nulls in reviews and ratings columns\n","cleaned_count = df_cleaned.shape[0] # Number of rows after dropping nulls\n","rows_dropped = original_count - cleaned_count\n","\n","print(f\"Number of rows dropped: {rows_dropped}\")\n","\n","# Get the shape after dropping null values\n","df_shape_after_dropping = df_cleaned.shape\n","\n","print(f\"Shape of the DataFrame after dropping rows: {df_shape_after_dropping}\")\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Longest review length: 668 words\n","Shortest review length: 20 words\n","Shape of the DataFrame after dropping rows below 20 words: (32857, 10)\n"]}],"source":["# Add a new column 'Review_length' to df_cleaned with the length of each review\n","df_cleaned['Review_length'] = df_cleaned['Review'].apply(lambda x: len(str(x).split()))\n","\n","df_cleaned = df_cleaned.copy() # To fix error\n","\n","# Filter out reviews that are shorter than 20 words from df_cleaned\n","df_cleaned.drop(df_cleaned[df_cleaned['Review_length'] < 20].index, inplace=True)\n","\n","# Longest and shortest reviews in df_cleaned\n","longest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmax()]\n","longest_review = longest_review_row['Review']\n","longest_review_length = longest_review_row['Review_length']\n","\n","shortest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmin()]\n","shortest_review = shortest_review_row['Review']\n","shortest_review_length = shortest_review_row['Review_length']\n","\n","\n","print(f\"Longest review length: {longest_review_length} words\")\n","print(f\"Shortest review length: {shortest_review_length} words\")\n","print(f\"Shape of the DataFrame after dropping rows below 20 words: {df_cleaned.shape}\")\n","\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n"]}],"source":["# Tokenization and stop words removal\n","stop_words = set(stopwords.words('english'))\n","\n","# Function to clean and process the text\n","def clean_review(review):\n","    review = str(review).lower()\n","    review = review.translate(str.maketrans('', '', string.punctuation))\n","    # Tokenize and remove stop words\n","    words = word_tokenize(review)\n","    words = [word for word in words if word.isalpha() and word not in stop_words]\n","    # Join back into a string\n","    review = ' '.join(words)\n","    return review\n","\n","\n","print(f\"Done\")"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total dataset size: 49124\n","Train size: 39299 (80.00%)\n","Test size: 9825 (20.00%)\n"]}],"source":["# Feature Extraction\n","tfidf = TfidfVectorizer(max_features=5000)\n","X = tfidf.fit_transform(df['Processed_Reviews']).toarray()\n","\n","# Negative is 0 = 1 and 2 rating \n","# Neutral is 1 = 3 rating\n","# Positive is 2 = 4 and 5 rating\n","\n","df = df.dropna(subset=['Processed_Reviews'])\n","df = df.dropna(subset=['Cons_rating'])\n","X = df['Processed_Reviews']\n","y = df['Cons_rating']\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', max_df=0.95, min_df=0.05)\n","\n","# Fit the vectorizer on the training data and transform it\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)\n","\n","print(f\"Total dataset size: {len(X)}\")\n","print(f\"Train size: {len(X_train)} ({len(X_train)/len(X)*100:.2f}%)\")\n","print(f\"Test size: {len(X_test)} ({len(X_test)/len(X)*100:.2f}%)\")"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Apply SMOTE to the training data\n","X_tfidf = tfidf_vectorizer.fit_transform(df['Processed_Reviews'])\n","smote = SMOTE(random_state=42)\n","# X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","X_resampled, y_resampled = smote.fit_resample(X_tfidf, y_encoded)"]},{"cell_type":"markdown","metadata":{},"source":["Train the Naive Bayes classifier"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5782188295165395\n"]}],"source":["# Model Training -------------------------- Fix error --------------------------------------------------------\n","model = MultinomialNB()\n","\n","model.fit(X_train_tfidf, y_train)\n","\n","# Predictions\n","y_pred = model.predict(X_test_tfidf)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Basline model"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Review: Absolutely wonderful - silky and sexy and comfortable\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n","Predicted Sentiment: Neutral\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n"]}],"source":["# Sentiment\n","df['Sentiment_Summary'] = df['Cons_rating'].apply(lambda x: 'Negative' if x < 3 else ('Neutral' if x == 3 else 'Positive'))\n","\n","\n","# Display the first 5 reviews with their predicted sentiments \n","for index, row in df.head(5).iterrows():\n","    print(\"Original Review:\", row['Review'])\n","    print(\"Predicted Sentiment:\", row['Sentiment_Summary'])\n","    print('-' * 100)\n"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Review: Absolutely wonderful - silky and sexy and comfortable\n","Original Review Word Count: 8\n","Summarized Review: Absolutely wonderful - silky and sexy and comfortable\n","Summarized Review Word Count: 8\n","----------------------------------------------------------------------------------------------------\n","Original Review: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n","Original Review Word Count: 62\n","Summarized Review: i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite. would definitely be a true midi on someone who is truly petite.\n","Summarized Review Word Count: 36\n","----------------------------------------------------------------------------------------------------\n","Original Review: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n","Original Review Word Count: 98\n","Summarized Review: i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. i initially ordered the petite small (my usual size) but i found this to be outrageously small.\n","Summarized Review Word Count: 53\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n","Original Review Word Count: 22\n","Summarized Review: every time i wear it, i get nothing but great compliments! it's fun, flirty, and fabulous!\n","Summarized Review Word Count: 16\n","----------------------------------------------------------------------------------------------------\n","Original Review: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n","Original Review Word Count: 36\n","Summarized Review: it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. This shirt is very flattering to all due to the adjustable front tie.\n","Summarized Review Word Count: 33\n","----------------------------------------------------------------------------------------------------\n"]}],"source":["# Summarize \n","\n","# Make sure its intaking sorted data\n","# Make sure they are intaking sentiment/rating\n","\n","def summarize_review(review, num_sentences=2):\n","\n","    stopWords = set(stopwords.words(\"english\"))\n","    words = word_tokenize(review.lower()) \n","\n","    freqTable = FreqDist(words)\n","    sentences = sent_tokenize(review)\n","    sentenceValue = dict()\n","\n","    for sentence in sentences:\n","        for word, freq in freqTable.items():\n","            if word in sentence.lower():\n","                if sentence in sentenceValue:\n","                    sentenceValue[sentence] += freq\n","                else:\n","                    sentenceValue[sentence] = freq\n","\n","    summary_sentences = nlargest(num_sentences, sentenceValue, key=sentenceValue.get)\n","    summary = ' '.join(summary_sentences)\n","    return summary\n","\n","df['Review'] = df['Review'].astype(str)\n","\n","# Apply the summarization function to your reviews\n","df['Summarized_Review'] = df['Review'].apply(summarize_review)\n","\n","# Print the first 5 original and summarized reviews\n","for index, row in df.head(5).iterrows():\n","    original_review = row['Review']\n","    summarized_review = row['Summarized_Review']\n","\n","    # Calculate word count\n","    original_word_count = len(original_review.split())\n","    summarized_word_count = len(summarized_review.split())\n","\n","    print(\"Original Review:\", original_review)\n","    print(\"Original Review Word Count:\", original_word_count)\n","    print(\"Summarized Review:\", summarized_review)\n","    print(\"Summarized Review Word Count:\", summarized_word_count)\n","    print('-' * 100)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
