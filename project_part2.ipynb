{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Consumer Reviews Summarization - Project Part 2\n","\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Ariamestra/ConsumerReviews/blob/main/project_part2.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ariamestra/ConsumerReviews/blob/main/project_part2.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction\n","My project goal is to develop a baseline model using a Naive Bayes classifier, designed to summarize customer reviews. This is intended to help potential buyers quickly navigate through reviews when assessing a product. The system will focus on condensing the essential content of each review and its associated rating into a concise, single-sentence comment. These comments will be categorized as positive, neutral, or negative, aligning with the review's original rating. This approach will simplify the review evaluation process, making it more efficient.<br>\n","<br>\n","**Data** <br>\n","The dataset was sourced from Kaggle, specifically the [Consumer Review of Clothing Product](https://www.kaggle.com/datasets/jocelyndumlao/consumer-review-of-clothing-product)\n"," dataset. This dataset includes customer reviews from Amazon. It has all sorts of feedback from buyers about different products. Along with the customers' actual reviews, ratings, product type, material, construction, color, finish, and durability.<br>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Prep"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape: (49338, 9)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Review</th>\n","      <th>Cons_rating</th>\n","      <th>Cloth_class</th>\n","      <th>Materials</th>\n","      <th>Construction</th>\n","      <th>Color</th>\n","      <th>Finishing</th>\n","      <th>Durability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4.0</td>\n","      <td>Intimates</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3.0</td>\n","      <td>Dresses</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5.0</td>\n","      <td>Pants</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5.0</td>\n","      <td>Blouses</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Title                                             Review  \\\n","0                      NaN  Absolutely wonderful - silky and sexy and comf...   \n","1                      NaN  Love this dress!  it's sooo pretty.  i happene...   \n","2  Some major design flaws  I had such high hopes for this dress and reall...   \n","3         My favorite buy!  I love, love, love this jumpsuit. it's fun, fl...   \n","4         Flattering shirt  This shirt is very flattering to all due to th...   \n","\n","   Cons_rating Cloth_class  Materials  Construction  Color  Finishing  \\\n","0          4.0   Intimates        0.0           0.0    0.0        1.0   \n","1          5.0     Dresses        0.0           1.0    0.0        0.0   \n","2          3.0     Dresses        0.0           0.0    0.0        1.0   \n","3          5.0       Pants        0.0           0.0    0.0        0.0   \n","4          5.0     Blouses        0.0           1.0    0.0        0.0   \n","\n","   Durability  \n","0         0.0  \n","1         0.0  \n","2         0.0  \n","3         0.0  \n","4         0.0  "]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# Import all of the Python Modules/Packages \n","#!pip install -U imbalanced-learn\n","\n","import pandas as pd\n","from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import string\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","from nltk.probability import FreqDist\n","from heapq import nlargest\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import SMOTE # Data transformer because when split traning data it 99% positive\n","\n","\n","\n","from nltk.probability import FreqDist\n","\n","\n","# Now download NLTK resources\n","#nltk.download('stopwords')\n","#nltk.download('punkt')\n","\n","data_URL = 'https://raw.githubusercontent.com/Ariamestra/ConsumerReviews/main/Reviews.csv'\n","df = pd.read_csv(data_URL)\n","print(f\"Shape: {df.shape}\")\n","df.head()"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nulls in the reviews: 831\n","Number of nulls in the ratings: 214\n","Number of rows dropped: 1043\n","Shape of the DataFrame after dropping rows: (48295, 9)\n"]}],"source":["# Count the number of nulls in reviews\n","number_of_nulls = df['Review'].isnull().sum()\n","print(f\"Number of nulls in the reviews: {number_of_nulls}\")\n","\n","# Calculate the number of nulls in rating\n","number_of_nulls_in_ratings = df['Cons_rating'].isnull().sum()\n","print(f\"Number of nulls in the ratings: {number_of_nulls_in_ratings}\")\n","\n","original_count = df.shape[0]\n","df_cleaned = df.dropna(subset=['Review', 'Cons_rating']) # Drop rows with nulls in reviews and ratings columns\n","cleaned_count = df_cleaned.shape[0] # Number of rows after dropping nulls\n","rows_dropped = original_count - cleaned_count\n","\n","print(f\"Number of rows dropped: {rows_dropped}\")\n","\n","# Get the shape after dropping null values\n","df_shape_after_dropping = df_cleaned.shape\n","\n","print(f\"Shape of the DataFrame after dropping rows: {df_shape_after_dropping}\")\n"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Longest review length: 668 words\n","Shortest review length: 20 words\n","Shape of the DataFrame after dropping rows below 20 words: (32857, 10)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1133/777670913.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_cleaned['Review_length'] = df_cleaned['Review'].apply(lambda x: len(str(x).split()))\n"]}],"source":["# Add a new column 'Review_length' to df_cleaned with the length of each review\n","df_cleaned['Review_length'] = df_cleaned['Review'].apply(lambda x: len(str(x).split()))\n","\n","df_cleaned = df_cleaned.copy() # To fix error\n","\n","# Filter out reviews that are shorter than 20 words from df_cleaned\n","df_cleaned.drop(df_cleaned[df_cleaned['Review_length'] < 20].index, inplace=True)\n","\n","# Longest and shortest reviews in df_cleaned\n","longest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmax()]\n","longest_review = longest_review_row['Review']\n","longest_review_length = longest_review_row['Review_length']\n","\n","shortest_review_row = df_cleaned.loc[df_cleaned['Review_length'].idxmin()]\n","shortest_review = shortest_review_row['Review']\n","shortest_review_length = shortest_review_row['Review_length']\n","\n","\n","print(f\"Longest review length: {longest_review_length} words\")\n","print(f\"Shortest review length: {shortest_review_length} words\")\n","print(f\"Shape of the DataFrame after dropping rows below 20 words: {df_cleaned.shape}\")\n","\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n"]}],"source":["# Tokenization and stop words removal\n","stop_words = set(stopwords.words('english'))\n","\n","# Function to clean and process the text\n","def clean_review(review):\n","    review = str(review).lower()\n","    review = review.translate(str.maketrans('', '', string.punctuation))\n","    # Tokenize and remove stop words\n","    words = word_tokenize(review)\n","    words = [word for word in words if word.isalpha() and word not in stop_words]\n","    # Join back into a string\n","    review = ' '.join(words)\n","    return review\n","\n","\n","print(f\"Done\")"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total dataset size: 32857\n","Train size: 26285 (80.00%)\n","Test size: 6572 (20.00%)\n"]}],"source":["# Apply the text cleaning function to create the 'Processed_Review' column\n","df_cleaned['Processed_Review'] = df_cleaned['Review'].apply(clean_review)\n","\n","# Initialize the TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', max_df=0.95, min_df=0.05)\n","\n","# Fit the vectorizer on the 'Processed_Review' column and transform it to get a feature matrix\n","X = tfidf_vectorizer.fit_transform(df_cleaned['Processed_Review'])\n","\n","# Encode the 'Cons_rating' column if it is categorical\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(df_cleaned['Cons_rating'])\n","\n","# Now that X and y are defined, you can split the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Calculate the total number \n","total_samples = X.shape[0]\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","\n","# Calculate the percentage \n","train_percentage = (train_size / total_samples) * 100\n","test_percentage = (test_size / total_samples) * 100\n","\n","# Print out the sizes and percentages of the full dataset, training, and test sets\n","print(f\"Total dataset size: {total_samples}\")\n","print(f\"Train size: {train_size} ({train_percentage:.2f}%)\")\n","print(f\"Test size: {test_size} ({test_percentage:.2f}%)\")\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["# Apply SMOTE to the training data\n","X_tfidf = tfidf_vectorizer.fit_transform(df_cleaned['Processed_Review'])\n","smote = SMOTE(random_state=42)\n","# X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","X_resampled, y_resampled = smote.fit_resample(X_tfidf, y_encoded)"]},{"cell_type":"markdown","metadata":{},"source":["Train the Naive Bayes classifier"]},{"cell_type":"markdown","metadata":{},"source":["Basline model"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5366707242848447\n"]}],"source":["# Model Training\n","model = MultinomialNB()\n","\n","# Correctly use X_train and y_train here\n","model.fit(X_train, y_train)\n","\n","# Predictions\n","# Use X_test for making predictions\n","y_pred = model.predict(X_test)\n","\n","# You should compare the predictions (y_pred) with the true labels (y_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Review: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n","Predicted Sentiment: Neutral\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n","Predicted Sentiment: Positive\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.\n","Predicted Sentiment: Negative\n","----------------------------------------------------------------------------------------------------\n"]}],"source":["# Sentiment\n","df['Sentiment_Summary'] = df['Cons_rating'].apply(lambda x: 'Negative' if x < 3 else ('Neutral' if x == 3 else 'Positive'))\n","\n","df['Review_length'] = df['Review'].apply(lambda x: len(str(x).split()))\n","\n","df_long_reviews = df[df['Review_length'] > 20]\n","\n","# Display the first 5 original reviews with more than 20 words\n","for index, row in df_long_reviews.head(5).iterrows():\n","    print(\"Original Review:\", row['Review'])\n","    # Assuming you have already created a 'Sentiment_Summary' column\n","    print(\"Predicted Sentiment:\", row['Sentiment_Summary'])\n","    print('-' * 100)\n"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Review: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n","Original Review Word Count: 62\n","Summarized Review: i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite. would definitely be a true midi on someone who is truly petite.\n","Summarized Review Word Count: 36\n","----------------------------------------------------------------------------------------------------\n","Original Review: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n","Original Review Word Count: 98\n","Summarized Review: i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. i initially ordered the petite small (my usual size) but i found this to be outrageously small.\n","Summarized Review Word Count: 53\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n","Original Review Word Count: 22\n","Summarized Review: every time i wear it, i get nothing but great compliments! it's fun, flirty, and fabulous!\n","Summarized Review Word Count: 16\n","----------------------------------------------------------------------------------------------------\n","Original Review: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n","Original Review Word Count: 36\n","Summarized Review: it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. This shirt is very flattering to all due to the adjustable front tie.\n","Summarized Review Word Count: 33\n","----------------------------------------------------------------------------------------------------\n","Original Review: I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.\n","Original Review Word Count: 98\n","Summarized Review: I love tracy reese dresses, but this one is not for the very petite. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment.\n","Summarized Review Word Count: 33\n","----------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1133/1547363213.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['Summarized_Review'] = df['Review'].apply(summarize_review)\n"]}],"source":["# ---------------------- Intaking sentiment -----------------------------\n","def summarize_review(review, num_sentences=2):\n","\n","    stopWords = set(stopwords.words(\"english\"))\n","    words = word_tokenize(review.lower()) \n","\n","    freqTable = FreqDist(words)\n","    sentences = sent_tokenize(review)\n","    sentenceValue = dict()\n","\n","    for sentence in sentences:\n","        for word, freq in freqTable.items():\n","            if word in sentence.lower():\n","                if sentence in sentenceValue:\n","                    sentenceValue[sentence] += freq\n","                else:\n","                    sentenceValue[sentence] = freq\n","\n","    summary_sentences = nlargest(num_sentences, sentenceValue, key=sentenceValue.get)\n","    summary = ' '.join(summary_sentences)\n","    return summary\n","df['Review'] = df['Review'].astype(str)\n","\n","# Calculate the word count for each review\n","df['Word_Count'] = df['Review'].apply(lambda x: len(x.split()))\n","\n","# Create a boolean mask for reviews with 20 words or more\n","mask = df['Word_Count'] >= 20\n","\n","# Apply the mask to the DataFrame to keep only the longer reviews\n","df = df[mask]\n","\n","# Apply the summarization function to your reviews\n","df['Summarized_Review'] = df['Review'].apply(summarize_review)\n","\n","# Print the first 5 original and summarized reviews\n","for index, row in df.head(5).iterrows():\n","    original_review = row['Review']\n","    summarized_review = row['Summarized_Review']\n","\n","    # Calculate word count\n","    original_word_count = len(original_review.split())\n","    summarized_word_count = len(summarized_review.split())\n","\n","    print(\"Original Review:\", original_review)\n","    print(\"Original Review Word Count:\", original_word_count)\n","    print(\"Summarized Review:\", summarized_review)\n","    print(\"Summarized Review Word Count:\", summarized_word_count)\n","    print('-' * 100)"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
